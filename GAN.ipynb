{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio de estágio em IA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "\n",
    "Nesta seção do código, está sendo utilizado um tipo especial de modelo de aprendizado de máquina chamado Rede Generativa Adversarial (GAN) para gerar previsões futuras. GANs consistem em um gerador e um discriminador que trabalham juntos para criar dados sintéticos realistas. Nesse contexto, o gerador gera amostras de dados futuros com base em um espaço de latente aleatório, enquanto o discriminador avalia a autenticidade dessas amostras.\n",
    "\n",
    "No início do código, a arquitetura do gerador e do discriminador é definida usando camadas densas da biblioteca Keras. O gerador recebe um vetor de latente como entrada e gera previsões de valores futuros. O discriminador, por sua vez, recebe amostras reais (dados históricos) e amostras geradas pelo gerador, atribuindo uma probabilidade de autenticidade a cada uma delas.\n",
    "\n",
    "Durante o treinamento da GAN, várias épocas são percorridas e os pesos do gerador e do discriminador são atualizados com base nas perdas calculadas. Após o treinamento, previsões futuras são geradas usando o gerador. Essas previsões são normalizadas e desnormalizadas para obter os valores reais em termos de preços de fechamento do mercado de ações."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações das bibliotecas usadas\n",
    "\n",
    "Nesse trecho de código, são importadas algumas bibliotecas e módulos necessários para o projeto.\n",
    "\n",
    "- `numpy` (importado como `np`) é uma biblioteca popular para computação numérica em Python, oferecendo suporte a arrays multidimensionais e uma ampla variedade de funções matemáticas.\n",
    "- `pandas` (importado como `pd`) é uma biblioteca usada para manipulação e análise de dados. Ela fornece estruturas de dados poderosas, como o DataFrame, que facilitam o trabalho com conjuntos de dados tabulares.\n",
    "- `tensorflow` (importado como `tf`) é uma biblioteca de código aberto amplamente utilizada para aprendizado de máquina e inteligência artificial. Ela oferece uma variedade de ferramentas e funcionalidades para construir, treinar e implantar modelos de aprendizado de máquina.\n",
    "- `tensorflow.keras.layers` é um módulo do TensorFlow que fornece uma API para criar camadas de redes neurais em modelos de aprendizado profundo.\n",
    "- `backtesting` é uma biblioteca que facilita o teste e a avaliação de estratégias de negociação em dados históricos de mercado. Ela fornece classes e métodos para realizar backtesting de estratégias, avaliar métricas de desempenho e visualizar os resultados.\n",
    "\n",
    "Essas importações são feitas para utilizar as funcionalidades dessas bibliotecas e módulos ao longo do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from backtesting import Backtest, Strategy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura do CSV\n",
    "\n",
    "Nesse trecho de código, é utilizada a biblioteca pandas para ler um arquivo CSV contendo dados relacionados ao preço do petróleo em 2021. A função `pd.read_csv()` é usada para carregar os dados do arquivo CSV e armazená-los em um objeto do tipo DataFrame. Em seguida, é selecionada apenas a coluna \"Close\" do DataFrame original e atribuída novamente à variável `dados`. Essa coluna representa os preços de fechamento do petróleo. Ao fazer isso, os dados são filtrados para utilizar apenas essa informação específica em análises ou processamentos posteriores. Essa operação é comum quando se deseja trabalhar com uma variável específica de um conjunto de dados mais amplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('dados_petroleo_2021.csv')\n",
    "dados = dados['Close']  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos dados\n",
    "\n",
    "Nesse trecho de código, é realizada a normalização dos dados. Primeiro, é subtraída a média dos dados (`dados.mean()`) de cada valor do conjunto de dados `dados`. Em seguida, o resultado é dividido pelo desvio padrão dos dados (`dados.std()`). Esse processo de normalização é comumente usado para colocar os dados em uma escala com média zero e desvio padrão igual a um. A normalização dos dados é útil em várias técnicas de análise e modelagem, pois ajuda a lidar com diferenças de escala entre as variáveis e permite compará-las de maneira mais adequada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados = (dados - dados.mean()) / dados.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparâmetros da GAN\n",
    "\n",
    "Comentário sobre os Hiperparâmetros da GAN:\n",
    "\n",
    "Neste trecho de código, são definidos os hiperparâmetros da Rede Generativa Adversarial (GAN). Os hiperparâmetros são valores configuráveis que afetam o comportamento e o desempenho do modelo.\n",
    "\n",
    "- A variável `dimensao_latente` representa a dimensão do vetor latente utilizado como entrada para o gerador da GAN. Essa dimensão determina a complexidade e a variabilidade das amostras sintéticas geradas pelo modelo. No caso desse código, o vetor latente tem dimensão 10.\n",
    "\n",
    "- A variável `epocas` indica o número de épocas de treinamento da GAN. Uma época corresponde a uma iteração completa sobre todo o conjunto de dados. Quanto maior o número de épocas, mais oportunidades o modelo tem para aprender e melhorar suas previsões. Neste caso, são definidas 300 épocas de treinamento.\n",
    "\n",
    "- A variável `tamanho_lote` especifica o tamanho do lote de dados utilizado em cada iteração durante o treinamento da GAN. Um lote é um conjunto de amostras processadas simultaneamente pelo modelo antes de atualizar os pesos. O tamanho do lote pode afetar a estabilidade do treinamento e o uso eficiente dos recursos computacionais. Neste código, o tamanho do lote é definido como 64.\n",
    "\n",
    "Esses hiperparâmetros podem ser ajustados de acordo com as necessidades específicas do problema e podem impactar o desempenho e a qualidade das previsões geradas pela GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensao_latente = 10\n",
    "epocas = 150\n",
    "tamanho_lote = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerador\n",
    "\n",
    "Nesse trecho de código, é definido um gerador da GAN, que é uma rede neural artificial sequencial composta por camadas densas (fully connected layers). A primeira camada possui 256 neurônios com função de ativação ReLU e recebe como entrada um vetor de dimensão_latente. A segunda camada possui 512 neurônios com função de ativação ReLU. A última camada possui um único neurônio com função de ativação linear, que produzirá a saída do gerador. Essa arquitetura define como um gerador indeterminado irá transformar o vetor latente em previsões futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerador = tf.keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(dimensao_latente,)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminador\n",
    "\n",
    "Nesse trecho de código, é definido um discriminador da GAN, que também é uma rede neural artificial sequencial composta por camadas densas. A primeira camada possui 512 neurônios com função de ativação ReLU e recebe como entrada um único valor. A segunda camada possui 256 neurônios com função de ativação ReLU. A última camada possui um único neurônio com função de ativação sigmoid, que produzirá a saída do discriminador. Essa arquitetura define como um discriminador indeterminado irá classificar se uma entrada é real ou gerada por um gerador indeterminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminador = tf.keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(1,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de perda e otimizadores\n",
    "\n",
    "Neste trecho de código, são definidas três variáveis:\n",
    "\n",
    "1. `funcao_perda` é uma instância da classe `BinaryCrossentropy` do módulo `tf.keras.losses`. Essa função de perda é comumente utilizada em problemas de classificação binária para calcular a diferença entre as previsões e os rótulos verdadeiros.\n",
    "2. `otimizador_gerador` é uma instância da classe `Adam` do módulo `tf.keras.optimizers`. Esse otimizador é responsável por atualizar os pesos do gerador durante o treinamento da GAN. A taxa de aprendizado (learning rate) definida é de 0.0001.\n",
    "3. `otimizador_discriminador` é outra instância da classe `Adam` do módulo `tf.keras.optimizers`. Esse otimizador é responsável por atualizar os pesos do discriminador durante o treinamento da GAN. Assim como o `otimizador_gerador`, a taxa de aprendizado definida é de 0.0001.\n",
    "\n",
    "Essas variáveis são essenciais para configurar a função de perda e os otimizadores que serão utilizados na GAN, contribuindo para a aprendizagem dos modelos gerador e discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcao_perda = tf.keras.losses.BinaryCrossentropy()\n",
    "otimizador_gerador = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "otimizador_discriminador = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de treinamento da GAN\n",
    "\n",
    "Neste trecho de código, é definida a função `treinar_gan`, decorada com `@tf.function`, indicando que ela será compilada em um grafo TensorFlow para otimização de desempenho. A função recebe `dados_reais` como entrada.\n",
    "\n",
    "A função realiza as seguintes etapas:\n",
    "\n",
    "1. Obtém o tamanho do lote a partir das dimensões dos `dados_reais`.\n",
    "2. Gera um vetor latente aleatório usando `tf.random.normal`, com o tamanho do lote e a dimensão latente desejada.\n",
    "3. Cria dois blocos de contexto com `tf.GradientTape()`, um para o gerador (`gerador_tape`) e outro para o discriminador (`discriminador_tape`).\n",
    "4. Dentro dos blocos de contexto, o gerador é utilizado para gerar dados sintéticos a partir do vetor latente.\n",
    "5. O discriminador é aplicado tanto aos dados reais quanto aos dados gerados para obter os resultados (`resultado_dados_reais` e `resultado_dados_gerados`, respectivamente).\n",
    "6. Calcula a perda do discriminador utilizando a função de perda (`funcao_perda`), somando a perda para os dados reais e a perda para os dados gerados.\n",
    "7. Calcula a perda do gerador utilizando a função de perda, considerando apenas os resultados dos dados gerados.\n",
    "8. Calcula os gradientes da perda em relação às variáveis treináveis do gerador e do discriminador, respectivamente.\n",
    "9. Aplica os gradientes aos otimizadores do gerador e do discriminador utilizando `apply_gradients`, atualizando os pesos das redes neurais.\n",
    "\n",
    "Em resumo, esse código implementa um passo de treinamento de uma rede GAN (Generative Adversarial Network), em que o gerador e o discriminador são treinados alternadamente para melhorar a qualidade dos dados gerados pelo gerador e a capacidade do discriminador em distinguir dados reais dos dados gerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def treinar_gan(dados_reais):\n",
    "    tamanho_lote = dados_reais.shape[0]\n",
    "    vetor_latente = tf.random.normal([tamanho_lote, dimensao_latente])\n",
    "\n",
    "    with tf.GradientTape() as gerador_tape, tf.GradientTape() as discriminador_tape:\n",
    "        dados_gerados = gerador(vetor_latente)\n",
    "\n",
    "        resultado_dados_reais = discriminador(dados_reais)\n",
    "        resultado_dados_gerados = discriminador(dados_gerados)\n",
    "\n",
    "        perda_discriminador = funcao_perda(tf.ones_like(resultado_dados_reais), resultado_dados_reais) + \\\n",
    "            funcao_perda(tf.zeros_like(resultado_dados_gerados), resultado_dados_gerados)\n",
    "        perda_gerador = funcao_perda(tf.ones_like(resultado_dados_gerados), resultado_dados_gerados)\n",
    "\n",
    "    gradientes_gerador = gerador_tape.gradient(perda_gerador, gerador.trainable_variables)\n",
    "    gradientes_discriminador = discriminador_tape.gradient(perda_discriminador, discriminador.trainable_variables)\n",
    "\n",
    "    otimizador_gerador.apply_gradients(zip(gradientes_gerador, gerador.trainable_variables))\n",
    "    otimizador_discriminador.apply_gradients(zip(gradientes_discriminador, discriminador.trainable_variables))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento da GAN\n",
    "\n",
    "Neste trecho de código, é realizado um loop de treinamento ao longo de um número especificado de épocas.\n",
    "\n",
    "Dentro de cada iteração do loop, os seguintes passos são executados:\n",
    "\n",
    "1. É gerado um índice aleatório usando `np.random.randint` para selecionar uma parte aleatória dos dados normalizados.\n",
    "2. Os dados reais são extraídos do conjunto de dados normalizados com base no índice aleatório gerado. Em seguida, os dados são remodelados para terem uma dimensão de (-1, 1).\n",
    "3. A função `treinar_gan` é chamada, passando os dados reais como entrada para treinar o modelo GAN.\n",
    "\n",
    "Após o treinamento em cada iteração, é verificado se o número da época atual é um múltiplo de 100 usando o operador `%`. Se a condição for verdadeira, uma mensagem indicando a época atual e o número total de épocas é exibida.\n",
    "\n",
    "Em resumo, este código implementa um loop de treinamento para uma GAN, onde a cada época um lote aleatório de dados é selecionado e o modelo é treinado utilizando esses dados. A cada 100 épocas, uma mensagem de progresso é exibida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0/150\n",
      "Época 100/150\n"
     ]
    }
   ],
   "source": [
    "for epoca in range(epocas):\n",
    "    indice_aleatorio = np.random.randint(0, len(dados_normalizados) - tamanho_lote)\n",
    "    dados_reais = dados_normalizados[indice_aleatorio:indice_aleatorio + tamanho_lote].values.reshape(-1, 1)\n",
    "\n",
    "    treinar_gan(dados_reais)\n",
    "\n",
    "    if epoca % 100 == 0:\n",
    "        print(f'Época {epoca}/{epocas}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar previsões futuras\n",
    "\n",
    "Neste trecho de código, é gerado um vetor latente aleatório utilizando `tf.random.normal`. O vetor latente tem uma forma de `[tamanho_lote, dimensao_latente]`, em que `tamanho_lote` representa o número de amostras e `dimensao_latente` é a dimensão do vetor latente.\n",
    "\n",
    "Em seguida, o gerador é utilizado para gerar previsões futuras com base nesse vetor latente. As previsões futuras são obtidas chamando a função `gerador` e passando o vetor latente como entrada.\n",
    "\n",
    "Resumindo, esse código gera um vetor latente aleatório e utiliza o gerador para produzir previsões futuras com base nesse vetor latente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_latente = tf.random.normal([tamanho_lote, dimensao_latente])\n",
    "previsoes_futuras = gerador(vetor_latente)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desnormalizar as previsões\n",
    "\n",
    "Neste trecho de código, a variável `previsoes_futuras` é convertida em um array NumPy usando o método `numpy()`. Em seguida, uma sequência de operações é aplicada para reverter a normalização que foi aplicada aos dados.\n",
    "\n",
    "Primeiro, é utilizado o método `reshape(-1)` para remodelar o array, transformando-o em um vetor unidimensional.\n",
    "\n",
    "Em seguida, é realizada a reversão da normalização nos valores do vetor `previsoes_futuras`. Isso é feito multiplicando o vetor pelos desvios padrão dos dados originais (`dados.std()`) e adicionando a média dos dados originais (`dados.mean()`).\n",
    "\n",
    "Por fim, o vetor `previsoes_futuras` é impresso utilizando a função `print()`.\n",
    "\n",
    "Em resumo, esse código desfaz a normalização aplicada às previsões futuras, levando em consideração a média e o desvio padrão dos dados originais, e imprime o resultado obtido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.402824 37.430283 34.185192 33.597233 34.10014  31.373726 37.209194\n",
      " 33.62356  41.92318  43.445293 37.199646 34.99151  30.219103 36.741707\n",
      " 34.39114  32.495598 34.5186   38.35016  33.713005 38.090263 36.614418\n",
      " 34.81481  39.225983 30.607853 42.51571  34.517586 31.275356 37.97146\n",
      " 42.996304 36.4609   36.20037  39.40197  31.03186  31.587234 46.37085\n",
      " 41.92871  31.854603 36.192894 37.656754 31.39125  34.919838 29.989609\n",
      " 34.110355 35.911617 34.405922 36.927986 36.60794  34.324352 31.953007\n",
      " 34.21318  38.06762  38.676933 38.71338  38.083855 32.712685 36.31541\n",
      " 34.429703 35.881187 39.145294 33.598274 34.99654  40.214397 33.895752\n",
      " 39.212578 38.279823 29.914124 40.021755 27.876888 38.76705  32.257645\n",
      " 35.229164 42.108932 34.168034 37.634003 33.30445  42.590233 40.111588\n",
      " 29.8979   37.771843 37.68519  37.205597 31.96833  43.96305  34.995903\n",
      " 32.939217 41.49228  41.79322  32.3222   27.746338 36.833252 38.52073\n",
      " 38.216816 39.723907 33.843937 35.039566 37.071815 34.540268 40.093925\n",
      " 31.882263 35.59793  35.312103 38.89441  36.745605 34.025116 47.333965\n",
      " 35.49614  40.965286 32.639656 39.549843 35.940845 40.975033 44.25609\n",
      " 44.89222  33.10659  40.50358  39.50131  45.056297 41.879498 33.05783\n",
      " 39.51942  33.408134 40.805634 43.21699  39.771477 38.42976  35.014137\n",
      " 36.2674   41.89558 ]\n"
     ]
    }
   ],
   "source": [
    "previsoes_futuras = previsoes_futuras.numpy().reshape(-1) * dados.std() + dados.mean()\n",
    "\n",
    "print(previsoes_futuras)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest - Cruzamento de médias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar datas para os dados futuros\n",
    "\n",
    "Neste trecho de código, a variável `ultima_data` é definida como a última data presente no índice dos dados.\n",
    "\n",
    "Em seguida, a variável `datas_futuras` é criada utilizando a função `pd.date_range()`. Essa função gera um intervalo de datas começando no dia seguinte à `ultima_data` adicionando um dia (`ultima_data + pd.DateOffset(days=1)`) e com um número de períodos igual ao tamanho do vetor `previsoes_futuras`. O uso do método `normalize()` garante que todas as datas no intervalo sejam definidas como meia-noite, descartando informações de tempo.\n",
    "\n",
    "Dessa forma, o código está criando um conjunto de datas futuras que correspondem às previsões geradas pelo modelo. Essas datas podem ser utilizadas para mapear as previsões futuras aos seus respectivos períodos de tempo, auxiliando na análise e visualização dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6782/758396369.py:2: UserWarning: Discarding nonzero nanoseconds in conversion.\n",
      "  datas_futuras = pd.date_range(start=ultima_data + pd.DateOffset(days=1), periods=len(previsoes_futuras)).normalize()\n"
     ]
    }
   ],
   "source": [
    "ultima_data = pd.to_datetime(dados.index[-1])\n",
    "datas_futuras = pd.date_range(start=ultima_data + pd.DateOffset(days=1), periods=len(previsoes_futuras)).normalize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar DataFrame para backtesting\n",
    "\n",
    "Neste trecho de código, é criado um DataFrame chamado `dados_backtesting` com duas colunas: 'Date', que contém as datas futuras, e 'Close', que contém as previsões futuras.\n",
    "\n",
    "Em seguida, o índice do DataFrame é definido como a coluna 'Date' usando o método `set_index('Date', inplace=True)`, que modifica o DataFrame atual, substituindo seu índice.\n",
    "\n",
    "Por fim, são adicionadas as colunas 'Open', 'High' e 'Low' ao DataFrame `dados_backtesting`, e todos os valores dessas colunas são preenchidos com os valores da coluna 'Close'.\n",
    "\n",
    "Essas etapas têm como objetivo criar um DataFrame que pode ser utilizado para realizar o backtesting de estratégias de negociação ou análises futuras com base nas previsões geradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_backtesting = pd.DataFrame({'Date': datas_futuras, 'Close': previsoes_futuras})\n",
    "dados_backtesting.set_index('Date', inplace=True)\n",
    "dados_backtesting['Open'] = dados_backtesting['High'] = dados_backtesting['Low'] = dados_backtesting['Close']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir a estratégia de backtesting (cruzamento de médias)\n",
    "\n",
    "Neste trecho de código, é definida a classe `MovingAverageCrossStrategy`, que herda da classe `Strategy`. Essa classe implementa uma estratégia de negociação baseada em cruzamento de médias móveis.\n",
    "\n",
    "No método `__init__`, são definidos os parâmetros da estratégia, como o tamanho da janela da média móvel rápida (`fast_ma_window`) e da média móvel lenta (`slow_ma_window`). Além disso, a variável `buy_signal_triggered` é inicializada como `False`, indicando que não há sinal de compra acionado.\n",
    "\n",
    "No método `next`, são realizadas as seguintes etapas:\n",
    "- O histórico de preços de fechamento é obtido a partir dos dados.\n",
    "- A média móvel rápida (`fast_ma`) é calculada utilizando os últimos `fast_ma_window` períodos.\n",
    "- A média móvel lenta (`slow_ma`) é calculada utilizando os últimos `slow_ma_window` períodos.\n",
    "\n",
    "Em seguida, são verificadas as condições de cruzamento das médias móveis. Se a média móvel rápida for maior que a média móvel lenta e o sinal de compra ainda não tiver sido acionado (`buy_signal_triggered == False`), é emitido um sinal de compra (`buy()`) e a variável `buy_signal_triggered` é atualizada para `True`.\n",
    "\n",
    "Por outro lado, se a média móvel rápida for menor que a média móvel lenta e o sinal de compra tiver sido acionado anteriormente (`buy_signal_triggered == True`), é emitido um sinal de venda (`sell()`) e a variável `buy_signal_triggered` é atualizada para `False`.\n",
    "\n",
    "Em resumo, essa classe implementa uma estratégia de cruzamento de médias móveis, onde um sinal de compra é acionado quando a média móvel rápida cruza acima da média móvel lenta, e um sinal de venda é acionado quando a média móvel rápida cruza abaixo da média móvel lenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingAverageCrossStrategy(Strategy):\n",
    "    def init(self):\n",
    "        self.fast_ma_window = 50  # Janela da média móvel rápida\n",
    "        self.slow_ma_window = 200  # Janela da média móvel lenta\n",
    "        self.buy_signal_triggered = False\n",
    "\n",
    "    def next(self):\n",
    "        close_prices = self.data.Close\n",
    "        # Cálculo da média móvel rápida\n",
    "        fast_ma = close_prices[-self.fast_ma_window:].mean()\n",
    "        # Cálculo da média móvel lenta\n",
    "        slow_ma = close_prices[-self.slow_ma_window:].mean()\n",
    "\n",
    "        if fast_ma > slow_ma and not self.buy_signal_triggered:\n",
    "            self.buy()\n",
    "            self.buy_signal_triggered = True\n",
    "        elif fast_ma < slow_ma and self.buy_signal_triggered:\n",
    "            self.sell()\n",
    "            self.buy_signal_triggered = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executar o backtesting\n",
    "\n",
    "Neste código, é criada uma instância da classe `Backtest` chamada `bt`, que recebe os dados de backtesting `dados_backtesting` e a estratégia `MovingAverageCrossStrategy`.\n",
    "\n",
    "Em seguida, o método `run()` é chamado para executar o backtest com a estratégia definida.\n",
    "\n",
    "Por fim, o resultado do backtest é armazenado na variável `resultado` e é exibido usando `print(resultado)`.\n",
    "\n",
    "Em resumo, esse código realiza um backtest usando a estratégia de cruzamento de médias móveis (`MovingAverageCrossStrategy`) nos dados de backtesting (`dados_backtesting`), e o resultado do backtest é exibido. O resultado pode conter informações como o saldo inicial, saldo final, número de negociações realizadas, entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start                     1970-01-02 00:00:00\n",
      "End                       1970-05-09 00:00:00\n",
      "Duration                    127 days 00:00:00\n",
      "Exposure Time [%]                    60.15625\n",
      "Equity Final [$]                 10830.410927\n",
      "Equity Peak [$]                  12233.514259\n",
      "Return [%]                           8.304109\n",
      "Buy & Hold Return [%]               21.779479\n",
      "Return (Ann.) [%]                   25.542912\n",
      "Volatility (Ann.) [%]             2800.286119\n",
      "Sharpe Ratio                         0.009122\n",
      "Sortino Ratio                           0.165\n",
      "Calmar Ratio                         0.693765\n",
      "Max. Drawdown [%]                  -36.817836\n",
      "Avg. Drawdown [%]                  -25.520376\n",
      "Max. Drawdown Duration       23 days 00:00:00\n",
      "Avg. Drawdown Duration       11 days 00:00:00\n",
      "# Trades                                    1\n",
      "Win Rate [%]                            100.0\n",
      "Best Trade [%]                       8.321877\n",
      "Worst Trade [%]                      8.321877\n",
      "Avg. Trade [%]                       8.321877\n",
      "Max. Trade Duration          76 days 00:00:00\n",
      "Avg. Trade Duration          76 days 00:00:00\n",
      "Profit Factor                             NaN\n",
      "Expectancy [%]                       8.321877\n",
      "SQN                                       NaN\n",
      "_strategy                 MovingAverageCro...\n",
      "_equity_curve                             ...\n",
      "_trades                      Size  EntryBa...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "bt = Backtest(dados_backtesting, MovingAverageCrossStrategy)\n",
    "resultado = bt.run()\n",
    "\n",
    "print(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
