{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio de estágio em IA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "\n",
    "Nesta seção do código, está sendo utilizado um tipo especial de modelo de aprendizado de máquina chamado Rede Generativa Adversarial (GAN) para gerar previsões futuras. GANs consistem em um gerador e um discriminador que trabalham juntos para criar dados sintéticos realistas. Nesse contexto, o gerador gera amostras de dados futuros com base em um espaço de latente aleatório, enquanto o discriminador avalia a autenticidade dessas amostras.\n",
    "\n",
    "No início do código, a arquitetura do gerador e do discriminador é definida usando camadas densas da biblioteca Keras. O gerador recebe um vetor de latente como entrada e gera previsões de valores futuros. O discriminador, por sua vez, recebe amostras reais (dados históricos) e amostras geradas pelo gerador, atribuindo uma probabilidade de autenticidade a cada uma delas.\n",
    "\n",
    "Durante o treinamento da GAN, várias épocas são percorridas e os pesos do gerador e do discriminador são atualizados com base nas perdas calculadas. Após o treinamento, previsões futuras são geradas usando o gerador. Essas previsões são normalizadas e desnormalizadas para obter os valores reais em termos de preços de fechamento do mercado de ações."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações das bibliotecas usadas\n",
    "\n",
    "Nesse trecho de código, são importadas algumas bibliotecas e módulos necessários para o projeto.\n",
    "\n",
    "- `numpy` (importado como `np`) é uma biblioteca popular para computação numérica em Python, oferecendo suporte a arrays multidimensionais e uma ampla variedade de funções matemáticas.\n",
    "- `pandas` (importado como `pd`) é uma biblioteca usada para manipulação e análise de dados. Ela fornece estruturas de dados poderosas, como o DataFrame, que facilitam o trabalho com conjuntos de dados tabulares.\n",
    "- `tensorflow` (importado como `tf`) é uma biblioteca de código aberto amplamente utilizada para aprendizado de máquina e inteligência artificial. Ela oferece uma variedade de ferramentas e funcionalidades para construir, treinar e implantar modelos de aprendizado de máquina.\n",
    "- `tensorflow.keras.layers` é um módulo do TensorFlow que fornece uma API para criar camadas de redes neurais em modelos de aprendizado profundo.\n",
    "- `backtesting` é uma biblioteca que facilita o teste e a avaliação de estratégias de negociação em dados históricos de mercado. Ela fornece classes e métodos para realizar backtesting de estratégias, avaliar métricas de desempenho e visualizar os resultados.\n",
    "\n",
    "Essas importações são feitas para utilizar as funcionalidades dessas bibliotecas e módulos ao longo do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from backtesting import Backtest, Strategy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura do CSV\n",
    "\n",
    "Nesse trecho de código, é utilizada a biblioteca pandas para ler um arquivo CSV contendo dados relacionados ao preço do petróleo em 2021. A função `pd.read_csv()` é usada para carregar os dados do arquivo CSV e armazená-los em um objeto do tipo DataFrame. Em seguida, é selecionada apenas a coluna \"Close\" do DataFrame original e atribuída novamente à variável `dados`. Essa coluna representa os preços de fechamento do petróleo. Ao fazer isso, os dados são filtrados para utilizar apenas essa informação específica em análises ou processamentos posteriores. Essa operação é comum quando se deseja trabalhar com uma variável específica de um conjunto de dados mais amplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('dados_petroleo_2021.csv')\n",
    "dados = dados['Close']  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos dados\n",
    "\n",
    "Nesse trecho de código, é realizada a normalização dos dados. Primeiro, é subtraída a média dos dados (`dados.mean()`) de cada valor do conjunto de dados `dados`. Em seguida, o resultado é dividido pelo desvio padrão dos dados (`dados.std()`). Esse processo de normalização é comumente usado para colocar os dados em uma escala com média zero e desvio padrão igual a um. A normalização dos dados é útil em várias técnicas de análise e modelagem, pois ajuda a lidar com diferenças de escala entre as variáveis e permite compará-las de maneira mais adequada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados = (dados - dados.mean()) / dados.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparâmetros da GAN\n",
    "\n",
    "Comentário sobre os Hiperparâmetros da GAN:\n",
    "\n",
    "Neste trecho de código, são definidos os hiperparâmetros da Rede Generativa Adversarial (GAN). Os hiperparâmetros são valores configuráveis que afetam o comportamento e o desempenho do modelo.\n",
    "\n",
    "- A variável `dimensao_latente` representa a dimensão do vetor latente utilizado como entrada para o gerador da GAN. Essa dimensão determina a complexidade e a variabilidade das amostras sintéticas geradas pelo modelo. No caso desse código, o vetor latente tem dimensão 10.\n",
    "\n",
    "- A variável `epocas` indica o número de épocas de treinamento da GAN. Uma época corresponde a uma iteração completa sobre todo o conjunto de dados. Quanto maior o número de épocas, mais oportunidades o modelo tem para aprender e melhorar suas previsões. Neste caso, são definidas 150 épocas de treinamento.\n",
    "\n",
    "- A variável `tamanho_lote` especifica o tamanho do lote de dados utilizado em cada iteração durante o treinamento da GAN. Um lote é um conjunto de amostras processadas simultaneamente pelo modelo antes de atualizar os pesos. O tamanho do lote pode afetar a estabilidade do treinamento e o uso eficiente dos recursos computacionais. Neste código, o tamanho do lote é definido como 128.\n",
    "\n",
    "Esses hiperparâmetros podem ser ajustados de acordo com as necessidades específicas do problema e podem impactar o desempenho e a qualidade das previsões geradas pela GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensao_latente = 10\n",
    "epocas = 150\n",
    "tamanho_lote = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerador\n",
    "\n",
    "Nesse trecho de código, é definido um gerador da GAN, que é uma rede neural artificial sequencial composta por camadas densas (fully connected layers). A primeira camada possui 256 neurônios com função de ativação ReLU e recebe como entrada um vetor de dimensão_latente. A segunda camada possui 512 neurônios com função de ativação ReLU. A última camada possui um único neurônio com função de ativação linear, que produzirá a saída do gerador. Essa arquitetura define como um gerador indeterminado irá transformar o vetor latente em previsões futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerador = tf.keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(dimensao_latente,)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminador\n",
    "\n",
    "Nesse trecho de código, é definido um discriminador da GAN, que também é uma rede neural artificial sequencial composta por camadas densas. A primeira camada possui 512 neurônios com função de ativação ReLU e recebe como entrada um único valor. A segunda camada possui 256 neurônios com função de ativação ReLU. A última camada possui um único neurônio com função de ativação sigmoid, que produzirá a saída do discriminador. Essa arquitetura define como um discriminador indeterminado irá classificar se uma entrada é real ou gerada por um gerador indeterminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminador = tf.keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(1,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de perda e otimizadores\n",
    "\n",
    "Neste trecho de código, são definidas três variáveis:\n",
    "\n",
    "1. `funcao_perda` é uma instância da classe `BinaryCrossentropy` do módulo `tf.keras.losses`. Essa função de perda é comumente utilizada em problemas de classificação binária para calcular a diferença entre as previsões e os rótulos verdadeiros.\n",
    "2. `otimizador_gerador` é uma instância da classe `Adam` do módulo `tf.keras.optimizers`. Esse otimizador é responsável por atualizar os pesos do gerador durante o treinamento da GAN. A taxa de aprendizado (learning rate) definida é de 0.0001.\n",
    "3. `otimizador_discriminador` é outra instância da classe `Adam` do módulo `tf.keras.optimizers`. Esse otimizador é responsável por atualizar os pesos do discriminador durante o treinamento da GAN. Assim como o `otimizador_gerador`, a taxa de aprendizado definida é de 0.0001.\n",
    "\n",
    "Essas variáveis são essenciais para configurar a função de perda e os otimizadores que serão utilizados na GAN, contribuindo para a aprendizagem dos modelos gerador e discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcao_perda = tf.keras.losses.BinaryCrossentropy()\n",
    "otimizador_gerador = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "otimizador_discriminador = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de treinamento da GAN\n",
    "\n",
    "Neste trecho de código, é definida a função `treinar_gan`, decorada com `@tf.function`, indicando que ela será compilada em um grafo TensorFlow para otimização de desempenho. A função recebe `dados_reais` como entrada.\n",
    "\n",
    "A função realiza as seguintes etapas:\n",
    "\n",
    "1. Obtém o tamanho do lote a partir das dimensões dos `dados_reais`.\n",
    "2. Gera um vetor latente aleatório usando `tf.random.normal`, com o tamanho do lote e a dimensão latente desejada.\n",
    "3. Cria dois blocos de contexto com `tf.GradientTape()`, um para o gerador (`gerador_tape`) e outro para o discriminador (`discriminador_tape`).\n",
    "4. Dentro dos blocos de contexto, o gerador é utilizado para gerar dados sintéticos a partir do vetor latente.\n",
    "5. O discriminador é aplicado tanto aos dados reais quanto aos dados gerados para obter os resultados (`resultado_dados_reais` e `resultado_dados_gerados`, respectivamente).\n",
    "6. Calcula a perda do discriminador utilizando a função de perda (`funcao_perda`), somando a perda para os dados reais e a perda para os dados gerados.\n",
    "7. Calcula a perda do gerador utilizando a função de perda, considerando apenas os resultados dos dados gerados.\n",
    "8. Calcula os gradientes da perda em relação às variáveis treináveis do gerador e do discriminador, respectivamente.\n",
    "9. Aplica os gradientes aos otimizadores do gerador e do discriminador utilizando `apply_gradients`, atualizando os pesos das redes neurais.\n",
    "\n",
    "Em resumo, esse código implementa um passo de treinamento de uma rede GAN (Generative Adversarial Network), em que o gerador e o discriminador são treinados alternadamente para melhorar a qualidade dos dados gerados pelo gerador e a capacidade do discriminador em distinguir dados reais dos dados gerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def treinar_gan(dados_reais):\n",
    "    tamanho_lote = dados_reais.shape[0]\n",
    "    vetor_latente = tf.random.normal([tamanho_lote, dimensao_latente])\n",
    "\n",
    "    with tf.GradientTape() as gerador_tape, tf.GradientTape() as discriminador_tape:\n",
    "        dados_gerados = gerador(vetor_latente)\n",
    "\n",
    "        resultado_dados_reais = discriminador(dados_reais)\n",
    "        resultado_dados_gerados = discriminador(dados_gerados)\n",
    "\n",
    "        perda_discriminador = funcao_perda(tf.ones_like(resultado_dados_reais), resultado_dados_reais) + \\\n",
    "            funcao_perda(tf.zeros_like(resultado_dados_gerados), resultado_dados_gerados)\n",
    "        perda_gerador = funcao_perda(tf.ones_like(resultado_dados_gerados), resultado_dados_gerados)\n",
    "\n",
    "    gradientes_gerador = gerador_tape.gradient(perda_gerador, gerador.trainable_variables)\n",
    "    gradientes_discriminador = discriminador_tape.gradient(perda_discriminador, discriminador.trainable_variables)\n",
    "\n",
    "    otimizador_gerador.apply_gradients(zip(gradientes_gerador, gerador.trainable_variables))\n",
    "    otimizador_discriminador.apply_gradients(zip(gradientes_discriminador, discriminador.trainable_variables))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento da GAN\n",
    "\n",
    "Neste trecho de código, é realizado um loop de treinamento ao longo de um número especificado de épocas.\n",
    "\n",
    "Dentro de cada iteração do loop, os seguintes passos são executados:\n",
    "\n",
    "1. É gerado um índice aleatório usando `np.random.randint` para selecionar uma parte aleatória dos dados normalizados.\n",
    "2. Os dados reais são extraídos do conjunto de dados normalizados com base no índice aleatório gerado. Em seguida, os dados são remodelados para terem uma dimensão de (-1, 1).\n",
    "3. A função `treinar_gan` é chamada, passando os dados reais como entrada para treinar o modelo GAN.\n",
    "\n",
    "Após o treinamento em cada iteração, é verificado se o número da época atual é um múltiplo de 100 usando o operador `%`. Se a condição for verdadeira, uma mensagem indicando a época atual e o número total de épocas é exibida.\n",
    "\n",
    "Em resumo, este código implementa um loop de treinamento para uma GAN, onde a cada época um lote aleatório de dados é selecionado e o modelo é treinado utilizando esses dados. A cada 100 épocas, uma mensagem de progresso é exibida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0/150\n",
      "Época 10/150\n",
      "Época 20/150\n",
      "Época 30/150\n",
      "Época 40/150\n",
      "Época 50/150\n",
      "Época 60/150\n",
      "Época 70/150\n",
      "Época 80/150\n",
      "Época 90/150\n",
      "Época 100/150\n",
      "Época 110/150\n",
      "Época 120/150\n",
      "Época 130/150\n",
      "Época 140/150\n"
     ]
    }
   ],
   "source": [
    "for epoca in range(epocas):\n",
    "    indice_aleatorio = np.random.randint(0, len(dados_normalizados) - tamanho_lote)\n",
    "    dados_reais = dados_normalizados[indice_aleatorio:indice_aleatorio + tamanho_lote].values.reshape(-1, 1)\n",
    "\n",
    "    treinar_gan(dados_reais)\n",
    "\n",
    "    if epoca % 10 == 0:\n",
    "        print(f'Época {epoca}/{epocas}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar previsões futuras\n",
    "\n",
    "Neste trecho de código, é gerado um vetor latente aleatório utilizando `tf.random.normal`. O vetor latente tem uma forma de `[tamanho_lote, dimensao_latente]`, em que `tamanho_lote` representa o número de amostras e `dimensao_latente` é a dimensão do vetor latente.\n",
    "\n",
    "Em seguida, o gerador é utilizado para gerar previsões futuras com base nesse vetor latente. As previsões futuras são obtidas chamando a função `gerador` e passando o vetor latente como entrada.\n",
    "\n",
    "Resumindo, esse código gera um vetor latente aleatório e utiliza o gerador para produzir previsões futuras com base nesse vetor latente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_latente = tf.random.normal([tamanho_lote, dimensao_latente])\n",
    "previsoes_futuras = gerador(vetor_latente)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desnormalizar as previsões\n",
    "\n",
    "Neste trecho de código, a variável `previsoes_futuras` é convertida em um array NumPy usando o método `numpy()`. Em seguida, uma sequência de operações é aplicada para reverter a normalização que foi aplicada aos dados.\n",
    "\n",
    "Primeiro, é utilizado o método `reshape(-1)` para remodelar o array, transformando-o em um vetor unidimensional.\n",
    "\n",
    "Em seguida, é realizada a reversão da normalização nos valores do vetor `previsoes_futuras`. Isso é feito multiplicando o vetor pelos desvios padrão dos dados originais (`dados.std()`) e adicionando a média dos dados originais (`dados.mean()`).\n",
    "\n",
    "Por fim, o vetor `previsoes_futuras` é impresso utilizando a função `print()`.\n",
    "\n",
    "Em resumo, esse código desfaz a normalização aplicada às previsões futuras, levando em consideração a média e o desvio padrão dos dados originais, e imprime o resultado obtido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.586512 22.460976 20.365696 20.980324 22.805073 22.310526 22.849524\n",
      " 21.273417 23.626001 23.366646 24.057444 21.652637 20.913473 20.79905\n",
      " 23.118414 22.285988 23.279182 20.630163 22.523676 21.388988 27.719238\n",
      " 23.657763 23.214386 22.128666 21.117252 22.528849 22.236298 23.583553\n",
      " 21.007446 21.263449 22.198153 22.700161 22.973318 22.625158 23.275957\n",
      " 21.24421  21.980797 22.710535 23.123531 21.752947 22.381626 24.303997\n",
      " 21.465425 22.767675 21.31109  21.873402 24.447159 22.875668 22.883732\n",
      " 23.256102 22.321653 22.672398 21.633026 20.644176 23.265667 22.66707\n",
      " 21.726377 24.586588 23.375206 23.452528 22.029839 23.133669 22.7542\n",
      " 22.342123 23.423061 21.521685 23.21802  21.777098 24.749493 21.734793\n",
      " 23.944794 22.244255 24.39961  23.554207 22.113003 23.756962 20.985195\n",
      " 22.717316 23.393028 23.087238 22.595572 22.727722 21.354559 21.575428\n",
      " 22.984032 22.571228 21.567768 21.619278 22.369814 22.166035 21.801172\n",
      " 21.443169 22.850922 24.928234 22.670513 22.833815 22.157703 20.976486\n",
      " 21.624157 20.87312  22.435366 23.83741  21.37283  23.778496 21.925749\n",
      " 21.293705 21.382862 23.461926 22.681385 24.565903 21.895866 21.886244\n",
      " 21.607288 20.900135 22.638664 22.946928 22.848024 21.309677 23.294533\n",
      " 20.787771 23.366865 21.58747  22.058784 21.466902 23.677921 24.612188\n",
      " 21.122206 22.07349 ]\n"
     ]
    }
   ],
   "source": [
    "previsoes_futuras = previsoes_futuras.numpy().reshape(-1) * dados.std() + dados.mean()\n",
    "\n",
    "print(previsoes_futuras)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest - Cruzamento de médias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar datas para os dados futuros\n",
    "\n",
    "Neste trecho de código, a variável `ultima_data` é definida como a última data presente no índice dos dados.\n",
    "\n",
    "Em seguida, a variável `datas_futuras` é criada utilizando a função `pd.date_range()`. Essa função gera um intervalo de datas começando no dia seguinte à `ultima_data` adicionando um dia (`ultima_data + pd.DateOffset(days=1)`) e com um número de períodos igual ao tamanho do vetor `previsoes_futuras`. O uso do método `normalize()` garante que todas as datas no intervalo sejam definidas como meia-noite, descartando informações de tempo.\n",
    "\n",
    "Dessa forma, o código está criando um conjunto de datas futuras que correspondem às previsões geradas pelo modelo. Essas datas podem ser utilizadas para mapear as previsões futuras aos seus respectivos períodos de tempo, auxiliando na análise e visualização dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7424/758396369.py:2: UserWarning: Discarding nonzero nanoseconds in conversion.\n",
      "  datas_futuras = pd.date_range(start=ultima_data + pd.DateOffset(days=1), periods=len(previsoes_futuras)).normalize()\n"
     ]
    }
   ],
   "source": [
    "ultima_data = pd.to_datetime(dados.index[-1])\n",
    "datas_futuras = pd.date_range(start=ultima_data + pd.DateOffset(days=1), periods=len(previsoes_futuras)).normalize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar DataFrame para backtesting\n",
    "\n",
    "Neste trecho de código, é criado um DataFrame chamado `dados_backtesting` com duas colunas: 'Date', que contém as datas futuras, e 'Close', que contém as previsões futuras.\n",
    "\n",
    "Em seguida, o índice do DataFrame é definido como a coluna 'Date' usando o método `set_index('Date', inplace=True)`, que modifica o DataFrame atual, substituindo seu índice.\n",
    "\n",
    "Por fim, são adicionadas as colunas 'Open', 'High' e 'Low' ao DataFrame `dados_backtesting`, e todos os valores dessas colunas são preenchidos com os valores da coluna 'Close'.\n",
    "\n",
    "Essas etapas têm como objetivo criar um DataFrame que pode ser utilizado para realizar o backtesting de estratégias de negociação ou análises futuras com base nas previsões geradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_backtesting = pd.DataFrame({'Date': datas_futuras, 'Close': previsoes_futuras})\n",
    "dados_backtesting.set_index('Date', inplace=True)\n",
    "dados_backtesting['Open'] = dados_backtesting['High'] = dados_backtesting['Low'] = dados_backtesting['Close']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir a estratégia de backtesting (cruzamento de médias)\n",
    "\n",
    "Neste trecho de código, é definida a classe `MovingAverageCrossStrategy`, que herda da classe `Strategy`. Essa classe implementa uma estratégia de negociação baseada em cruzamento de médias móveis.\n",
    "\n",
    "No método `__init__`, são definidos os parâmetros da estratégia, como o tamanho da janela da média móvel rápida (`fast_ma_window`) e da média móvel lenta (`slow_ma_window`). Além disso, a variável `buy_signal_triggered` é inicializada como `False`, indicando que não há sinal de compra acionado.\n",
    "\n",
    "No método `next`, são realizadas as seguintes etapas:\n",
    "- O histórico de preços de fechamento é obtido a partir dos dados.\n",
    "- A média móvel rápida (`fast_ma`) é calculada utilizando os últimos `fast_ma_window` períodos.\n",
    "- A média móvel lenta (`slow_ma`) é calculada utilizando os últimos `slow_ma_window` períodos.\n",
    "\n",
    "Em seguida, são verificadas as condições de cruzamento das médias móveis. Se a média móvel rápida for maior que a média móvel lenta e o sinal de compra ainda não tiver sido acionado (`buy_signal_triggered == False`), é emitido um sinal de compra (`buy()`) e a variável `buy_signal_triggered` é atualizada para `True`.\n",
    "\n",
    "Por outro lado, se a média móvel rápida for menor que a média móvel lenta e o sinal de compra tiver sido acionado anteriormente (`buy_signal_triggered == True`), é emitido um sinal de venda (`sell()`) e a variável `buy_signal_triggered` é atualizada para `False`.\n",
    "\n",
    "Em resumo, essa classe implementa uma estratégia de cruzamento de médias móveis, onde um sinal de compra é acionado quando a média móvel rápida cruza acima da média móvel lenta, e um sinal de venda é acionado quando a média móvel rápida cruza abaixo da média móvel lenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingAverageCrossStrategy(Strategy):\n",
    "    def init(self):\n",
    "        self.fast_ma_window = 50  # Janela da média móvel rápida\n",
    "        self.slow_ma_window = 200  # Janela da média móvel lenta\n",
    "        self.buy_signal_triggered = False\n",
    "\n",
    "    def next(self):\n",
    "        close_prices = self.data.Close\n",
    "        # Cálculo da média móvel rápida\n",
    "        fast_ma = close_prices[-self.fast_ma_window:].mean()\n",
    "        # Cálculo da média móvel lenta\n",
    "        slow_ma = close_prices[-self.slow_ma_window:].mean()\n",
    "\n",
    "        if fast_ma > slow_ma and not self.buy_signal_triggered:\n",
    "            self.buy()\n",
    "            self.buy_signal_triggered = True\n",
    "        elif fast_ma < slow_ma and self.buy_signal_triggered:\n",
    "            self.sell()\n",
    "            self.buy_signal_triggered = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executar o backtesting\n",
    "\n",
    "Neste código, é criada uma instância da classe `Backtest` chamada `bt`, que recebe os dados de backtesting `dados_backtesting` e a estratégia `MovingAverageCrossStrategy`.\n",
    "\n",
    "Em seguida, o método `run()` é chamado para executar o backtest com a estratégia definida.\n",
    "\n",
    "Por fim, o resultado do backtest é armazenado na variável `resultado` e é exibido usando `print(resultado)`.\n",
    "\n",
    "Em resumo, esse código realiza um backtest usando a estratégia de cruzamento de médias móveis (`MovingAverageCrossStrategy`) nos dados de backtesting (`dados_backtesting`), e o resultado do backtest é exibido. O resultado pode conter informações como o saldo inicial, saldo final, número de negociações realizadas, entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start                     1970-01-02 00:00:00\n",
      "End                       1970-05-09 00:00:00\n",
      "Duration                    127 days 00:00:00\n",
      "Exposure Time [%]                    58.59375\n",
      "Equity Final [$]                 10691.787811\n",
      "Equity Peak [$]                  12073.483887\n",
      "Return [%]                           6.917878\n",
      "Buy & Hold Return [%]               -2.271362\n",
      "Return (Ann.) [%]                   21.014897\n",
      "Volatility (Ann.) [%]              160.612018\n",
      "Sharpe Ratio                         0.130843\n",
      "Sortino Ratio                        0.317348\n",
      "Calmar Ratio                         1.266093\n",
      "Max. Drawdown [%]                  -16.598225\n",
      "Avg. Drawdown [%]                  -12.716464\n",
      "Max. Drawdown Duration       34 days 00:00:00\n",
      "Avg. Drawdown Duration       19 days 00:00:00\n",
      "# Trades                                    1\n",
      "Win Rate [%]                            100.0\n",
      "Best Trade [%]                       6.923568\n",
      "Worst Trade [%]                      6.923568\n",
      "Avg. Trade [%]                       6.923568\n",
      "Max. Trade Duration          74 days 00:00:00\n",
      "Avg. Trade Duration          74 days 00:00:00\n",
      "Profit Factor                             NaN\n",
      "Expectancy [%]                       6.923568\n",
      "SQN                                       NaN\n",
      "_strategy                 MovingAverageCro...\n",
      "_equity_curve                             ...\n",
      "_trades                      Size  EntryBa...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "bt = Backtest(dados_backtesting, MovingAverageCrossStrategy)\n",
    "resultado = bt.run()\n",
    "\n",
    "print(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
